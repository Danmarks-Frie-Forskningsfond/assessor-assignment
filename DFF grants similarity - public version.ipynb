{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46336a4-a929-43db-ab4c-4888f0431f73",
   "metadata": {},
   "source": [
    "# DFF grants similarity: A Bag-of-Words Approach\n",
    "* Inspired by [SNSF Grant Similarity](https://github.com/snsf-data/snsf-grant-similarity/blob/main/notebooks/grant_similarity_tfidf.ipynb)core\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6ce64-9ef9-48b4-a501-6473fe24eb88",
   "metadata": {},
   "source": [
    "The following notebook is based on SNSF's grants similarity notebook. The code is turned into functions that can be called making it easier to use on new datasets and for new purposes. \n",
    "\n",
    "The algorithm for detecting similarity is the same:\n",
    "\n",
    "1. pre-process the texts for the tf-idf model: english texts, lower casing, stop words and punctuation removal, stemming, n-grams\n",
    "2. apply the tf-idf weighting model and extract the tf-idf vectors\n",
    "3. compute the cosine similarity between the tf-idf vectors\n",
    "4. rank the texts based on the similarity score\n",
    "\n",
    "The functions take a set of baseline and comparison texts as input. Each is a dictionary containing an id key and a text key. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd600536-0c84-4a95-b2c1-ed652eeabacd",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "First, we import the neccessary libraries for data wrangling and natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fcca3-9260-4c3c-819f-9d4786f7464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "# import NLP/text libraries\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# import tfidf vectorizer and similarity metrics from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# and lanuage detection\n",
    "from langdetect import detect\n",
    "\n",
    "# import OpenAlex libraries\n",
    "import pyalex\n",
    "from pyalex import Works, Authors, Sources, Institutions, Topics, Publishers, Funders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db6129-2329-4d8a-98c4-2e2aacc4e150",
   "metadata": {},
   "source": [
    "## Setup stopwords dictionary and load the Porter stemmer\n",
    "In order to filter out stop words from the texts, we need to download the dictionary of stopwords available in the 'nltk' package (Bird et al., 2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04cb19-60c0-4275-9ba9-3bc549e1058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords if not already done\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d2c53-253d-49b9-acbe-e7427a1a5fbf",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "We perform some data wrangling first as we remove non-english texts and concatenate the texts of titles and abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4aef39-c749-4d6e-b6ef-6080e83622fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(data):\n",
    "    # concatenate titles and abstracts\n",
    "    data['TitleAbstract'] = data.Title + '. ' + data.Abstract\n",
    "    # detect language of titles and abstracts\n",
    "    data['Lang'] = data.TitleAbstract.apply(detect)\n",
    "    # keep only english texts\n",
    "    data = data[data.Lang == 'en']\n",
    "    # extract texts as a list\n",
    "    texts = data.TitleAbstract.tolist()\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc50bc-90e3-4a8d-b1be-28bf552cf801",
   "metadata": {},
   "source": [
    "## Text Processing and Tokenizer\n",
    "We begin the text pre-processing by removing the punctuation and further create the so-called unigrams by splitting the text sequence into separate words (tokens), while removing stop words and performing stemming of the remaining words. \n",
    "\n",
    "Additionally to the unigrams, we create short word combinations called n-grams, up to n=3, i.e. combinations of 3 words. As with unigrams, we perform stemming, but keep the stopwords.\r\n",
    "Finally, we concatenate the unigrams with n-grams to complete the tokenization process.\r\n",
    "\r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a01537-f6af-49c5-a782-dfd03c267263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(texts, use_stopwords=True, use_ngrams=True, n_grams=3):\n",
    "    \"\"\"\n",
    "    Preprocess a list of texts:\n",
    "      - Lowercases text.\n",
    "      - Removes punctuation.\n",
    "      - Optionally removes stopwords and applies stemming for unigrams.\n",
    "      - Optionally creates n-grams (with stemming) without stop word removal.\n",
    "      - Returns a list of token lists for each text.\n",
    "    \"\"\"\n",
    "    \n",
    "    processed_tokens = []\n",
    "    \n",
    "    for text in texts:\n",
    "        # Lowercase and remove punctuation (string.punctuation: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "        text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Unigrams: tokenize, remove stopwords and stem (if desired)\n",
    "        words = text.split()\n",
    "        if use_stopwords:\n",
    "            words = [word for word in words if word not in stop_words]\n",
    "        unigrams = [ps.stem(word) for word in words if len(word) > 1]\n",
    "        \n",
    "        tokens = unigrams.copy()\n",
    "        \n",
    "        # Create n-grams if desired\n",
    "        if use_ngrams and n_grams > 1:\n",
    "            # First, stem the words (without removing stopwords this time)\n",
    "            words_stemmed = [ps.stem(word) for word in text.split()]\n",
    "            # Create n-grams from 2 up to n_grams\n",
    "            ngrams = nltk.everygrams(words_stemmed, 2, n_grams)\n",
    "            ngrams = [' '.join(gram) for gram in ngrams]\n",
    "            tokens.extend(ngrams)\n",
    "        \n",
    "        processed_tokens.append(tokens)\n",
    "    return processed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36043214-c612-4c28-8ba9-88a47a251d25",
   "metadata": {},
   "source": [
    "## TF-IDF Model and similarity metric\r\n",
    "In order to create a numerical representation of the tokens, we apply the so-called TF-IDF (Term Frequency â€“ Inverse Document Frequency) weighting (Sparck Jones, 1972). TF-IDF is a type of bag-of-words approach, where the numerical representation of the text in vector space is based on a token decomposition of the text, ignoring the sequential nature of the text. This corresponds to the tokenization procedure conducted above. The TF-IDF then applies a weighting scheme that puts a higher weight on words that appear frequently in one document, but rarely across documents. The TF-IDF vectorization results in high-dimensional sparse vectors. Such TF-IDF vectorization has proven to be very effective in text similarity tasks, despite its simplicity (compare e.g. Shahmirzadi et al, 2019).\r",
    "In order to compare the similarity of the grants represented by the TF-IDF vectors, we compute the cosine distance between the vectors.\r\n",
    "\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e9185-52f6-4d51-a02b-a1919959d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(baseline_texts, comparison_texts):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity between the baseline set and the comparison set.\n",
    "    Returns a similarity matrix (rows: baseline, columns: comparison) along with the fitted vectorizer.\n",
    "    \"\"\"\n",
    "    # Preprocess both sets of texts\n",
    "    baseline_tokens = preprocess_texts(baseline_texts)\n",
    "    comparison_tokens = preprocess_texts(comparison_texts)\n",
    "    \n",
    "    # Combine tokens to fit a common vocabulary\n",
    "    combined_tokens = baseline_tokens + comparison_tokens\n",
    "    \n",
    "    # Initialize the TF-IDF vectorizer (using identity functions since tokens are precomputed)\n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x, use_idf=True, norm='l2')\n",
    "    tfidf_vector = tfidf.fit_transform(combined_tokens)\n",
    "    \n",
    "    # Split the vectors back into baseline and comparison sets\n",
    "    baseline_vector = tfidf_vector[:len(baseline_tokens)]\n",
    "    comparison_vector = tfidf_vector[len(baseline_tokens):]\n",
    "    \n",
    "    # Compute cosine similarity (each row corresponds to a baseline text and each column to a comparison text)\n",
    "    similarity_matrix = cosine_similarity(baseline_vector, comparison_vector)\n",
    "    return similarity_matrix, tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b00387-73e0-4fbd-ae57-0a91d6f86e4e",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "To retrieve the most similar grants relative to a target grant of interest, we rank-order the grants according to their cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c3a5a-6723-4da4-9cfe-cbb151704f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_matches(similarity_matrix, baseline_ids, comparison_ids, top_n=1):\n",
    "    \"\"\"\n",
    "    For each comparison case, find the top_n matching baseline items.\n",
    "    Returns a dictionary mapping each comparison ID (e.g. case number) to a list of best matching baseline IDs.\n",
    "    \"\"\"\n",
    "    matches = {}\n",
    "    # For each column (comparison case) in the similarity matrix...\n",
    "    for j, comp_id in enumerate(comparison_ids):\n",
    "        col_sim = similarity_matrix[:, j]\n",
    "        # Get indices of top_n highest similarity scores\n",
    "        top_indices = col_sim.argsort()[::-1][:top_n]\n",
    "        best_match_ids = [baseline_ids[i] for i in top_indices]\n",
    "        matches[comp_id] = best_match_ids\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a353b9-9f12-4797-b262-d7847e105280",
   "metadata": {},
   "source": [
    "# Reviewer suggestions\n",
    "Below is an implementation of the above algorithm that fetches data from our database on grants and reviewers. For the reviewers it downloads abstracts from OpenALEX in order to do the similarity ranking.\n",
    "\n",
    "In order to make the Notebook produce any output you need to complete the following functions:\n",
    "\n",
    "* def establish_database_conn()\n",
    "* def fetch_members()\n",
    "* def fetch_applications()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce1d8d-4ab9-4b9f-a6c8-34d109ed7772",
   "metadata": {},
   "source": [
    "## SQL-connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a8ea6-bf9e-452f-b45a-633e4ef4672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SQl libraries\n",
    "from sqlalchemy import URL, create_engine\n",
    "\n",
    "def establish_database_conn():\n",
    "    # Entern information to retrieve data from SQL database\n",
    "    return engine\n",
    "\n",
    "engine = establish_database_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acae5a-3d68-4f01-80d5-89499a7eee5c",
   "metadata": {},
   "source": [
    "### Fetch data about reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28562d-b6aa-4bc0-ac55-6db86b4ed925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_members():\n",
    "    # Return SQL query with the column name \"Navn\" for each member. \n",
    "    return pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce446a15-54fb-40f2-a305-f91d41b46a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_member_publications(name):\n",
    "    author = Authors().search_filter(display_name=name).get()\n",
    "\n",
    "    if author and \"id\" in author[0]:  # Hvis forfatteren findes\n",
    "        author_id = author[0][\"id\"]  # OpenAlex ID\n",
    "\n",
    "        works = Works().filter(author={\"id\": author_id}).get(per_page=200)\n",
    "        \n",
    "        data = []\n",
    "        \n",
    "        for work in works:\n",
    "            abstract = work[\"abstract\"]\n",
    "            title = work[\"title\"]\n",
    "            data.append([name, title, abstract])\n",
    "        \n",
    "        df = pd.DataFrame(data, columns=[\"Name\", \"Title\", \"Abstract\"])\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "    return pd.DataFrame(columns=[\"Name\", \"Title\", \"Abstract\"])  # Return empty DF if no publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316bb6b-c9e5-41ca-81d3-20afcac25257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_publicationdata(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"Using existing publications data\")\n",
    "        return pd.read_excel(file_path)\n",
    "        \n",
    "    else:\n",
    "        print(\"Exisiting publications data do not exist. Fetching records for all members from OpenALEX\")\n",
    "        # Fetch all members\n",
    "        members_df = fetch_members()\n",
    "        \n",
    "        # Loop through each member and get their publications\n",
    "        all_publications = []\n",
    "        \n",
    "        for _, row in tqdm(members_df.iterrows(), total=len(members_df), desc=\"Fetching Publications\", unit=\"member\"):\n",
    "            name = row[\"Navn\"]\n",
    "            publications_df = fetch_member_publications(name)\n",
    "            all_publications.append(publications_df)\n",
    "        \n",
    "        # Combine all publication data into a single DataFrame\n",
    "        final_df = pd.concat(all_publications, ignore_index=True)\n",
    "        final_df.to_excel(file_path, index=False)\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678707ff-094d-4e53-bf28-0f0e0a231115",
   "metadata": {},
   "source": [
    "### Fetch data about applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dececc-5629-4953-b50b-54ab0b93761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_applications():\n",
    "    # Return dataframe with grants or applications to be processed. The script expects the following columns:\n",
    "    # case_number\n",
    "    # Text\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e618a3a-2d79-4f74-b714-6da14404cf86",
   "metadata": {},
   "source": [
    "## Compare applications to reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edc628-31c5-4b46-8f76-676765cc9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch reviewers\n",
    "publications = load_publicationdata(\"reviewer_publications.xlsx\")\n",
    "reviewer_data = publications.apply(lambda row: {'id': row['Name'], 'text': f\"{row['Title']} {row['Abstract']}\"}, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05e376-46b4-4004-8328-47fbb0e2f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch applications\n",
    "applications = fetch_applications()\n",
    "grant_application_data = applications.apply(lambda row: {'case_number': row['case_number'], 'text': row['text']}, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cb10b-5a52-46f4-b309-2e4fb510e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract texts and IDs for baseline (reviewers) and comparison (grant applications)\n",
    "reviewer_texts = [item['text'] for item in reviewer_data]\n",
    "reviewer_ids = [item['id'] for item in reviewer_data]\n",
    "grant_texts = [item['text'] for item in grant_application_data]\n",
    "grant_ids = [item['case_number'] for item in grant_application_data]\n",
    "\n",
    "# Compute similarity: rows correspond to reviewers, columns to grant applications.\n",
    "similarity_matrix, _ = compute_similarity(reviewer_texts, grant_texts)\n",
    "\n",
    "# Rank matches: for each grant application, identify the best matching reviewer(s)\n",
    "matches = rank_matches(similarity_matrix, reviewer_ids, grant_ids, top_n=3)\n",
    "\n",
    "print(\"Best reviewer match for each grant application:\")\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777330b0-3f92-4f64-8c3c-39c2b4b43dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2fbec-92e4-44e1-bf3e-92894a538d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matches).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5a37a-7825-44df-8875-6eeb042ab3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"matches.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
